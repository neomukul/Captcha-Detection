# -*- coding: utf-8 -*-
"""Mukul_Captcha

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16tsfcB7WiDfXnD7YAJhDKG0E744oeQrj
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai.metrics import error_rate
from fastai.vision import *

import matplotlib.pyplot as plt
import cv2
import numpy as np
import pathlib
from torchsummary import summary
import torch.nn as nn
import torch

USE_GPU = True
if USE_GPU and torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')

print('using device:', device)

path_img = pathlib.PosixPath('/content/gdrive/My Drive/samples/') # give path of all the pic

fnames = get_image_files(path_img)
print(fnames[:5])

src = ImageList(fnames, path=path_img).split_by_rand_pct(0.2, seed=1111)

print(src)

def my_func(fpath):
  name = fpath.name
  split_name = [f"{i}_{char}" for i, char in enumerate(name)]
  return split_name

bs = 256
ds_tfms = get_transforms(do_flip=False, max_rotate=5)
src = ImageList(fnames, path=path_img).split_by_rand_pct(0.2, seed=1111)
data = ImageDataBunch.create_from_ll(src.label_from_func(my_func), ds_tfms=ds_tfms, tfm_y=False, size=(48,192), bs=bs).normalize(imagenet_stats)

data

data.show_batch(3)

model = models.resnet18(pretrained=True)

model.cuda()

summary(model, input_size=(3, 48, 192))

cnnModel = nn.Sequential(*list(model.children())[:-3])

summary(cnnModel, input_size=(3, 48, 192))

num_cls = 19+2
cols = 12
class OCR(nn.Module):
  def __init__(self, *args):
    super(OCR, self).__init__()
    modelResnet18 = models.resnet18(pretrained=True)
    self.cnnModel = nn.Sequential(*list(modelResnet18.children())[:-3])
    self.adapter = nn.Sequential(nn.Dropout(0.2), nn.BatchNorm1d(num_features = 256*3), nn.Linear(in_features=256*3, out_features=32)) #todo 768x12 -> 32x12
    self.bi_gru = nn.GRU(input_size = 32, hidden_size = 512, bidirectional=True, dropout=0.1, num_layers=2, batch_first=True)
    self.finalAdapter = nn.Sequential(nn.Dropout(0.5), nn.BatchNorm1d(num_features=512*2), nn.Linear(in_features=1024, out_features=num_cls), nn.LogSoftmax(dim=1))

  def forward(self, x):
    x = self.cnnModel.forward(x) #self.cnnModel(x)
    x = x.view(-1, 256*3, cols)
    rnnInput = torch.zeros(x.shape[0], cols, 32).to(x.device)
    for i in range(cols):
      tmp = x[:, :, i]
      tmp = torch.reshape(tmp, (tmp.shape[0], 256*3))
      tmp = self.adapter.forward(tmp)
      rnnInput[:, i, :] = tmp
    
    (x, hn) = self.bi_gru(rnnInput)
    res = torch.zeros(cols, x.shape[0], num_cls).to(x.device)
    for i in range(cols):
      tmp = x[:, i, :]
      tmp = self.finalAdapter.forward(tmp)
      res[i, :, :] = tmp
    return res

dataTest = torch.zeros((128, 3, 48, 192))
ocrModel = OCR()
ocrModel(dataTest).shape

ctc_loss = torch.nn.CTCLoss()
T = cols
C = num_cls
S = 7
S_min = 5
padSymbol = 1

def ocr_ctc(input, target):
  N = input.shape[1]
  target_lengths = torch.full((N,), S_min, dtype=torch.int32).cpu()
  input_lengths = torch.full((N,), T, dtype=torch.int32).cpu()
  log_probs = input.cpu()
  targets = torch.full((N,S), padSymbol, dtype=torch.long)
  for i in range(0,5):
    start = i * 19
    end = (i + 1) * 19
    t = target[:, start:end]
    targets[:, i] = 2 + t.argmax(dim=-1).long()

  loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)
  return loss

learn = Learner(data, ocrModel, layer_groups=[ocrModel.cnnModel, ocrModel.adapter, ocrModel.bi_gru, ocrModel.finalAdapter])
learn.loss_func = ocr_ctc

learn.freeze_to(1)
learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(100, 5e-2)

from fastai.callbacks.tracker import SaveModelCallback
from fastai.train import ShowGraph
learn.callbacks = [SaveModelCallback(learn), ShowGraph(learn)]
learn.metrics = []

learn.load('bestmode')
learn.save('stage_1')
learn.unfreeze()

learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(100, max_lr=[1e-3, 3e-3, 5e-3, 1e-2])

# second approach

from google.colab import drive
drive.mount('/content/gdrive')

from fastai import *
from fastai.metrics import error_rate
from fastai.vision import *
import matplotlib.pyplot as plt
import cv2
import numpy as np
import pathlib
import os
import torch.nn as nn
import torch
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

print(os.listdir("/content/gdrive/My Drive/samples/")[:10])

#src = ImageList(fnames, path=path_img).split_by_rand_pct(0.2, seed=1111)

path = Path(r'/content/gdrive/My Drive/samples/')

def label_from_filename(path):
    label = [char for char in path.name[:-4]]
    return label

data = (ImageList.from_folder(path)
        .split_by_rand_pct(0.2)
        .label_from_func(label_from_filename)
        .transform(get_transforms(do_flip=False))
        .databunch()
        .normalize()
       )
data.show_batch(3)

acc_02 = partial(accuracy_thresh, thresh=0.2)

learn = cnn_learner(data, models.resnet18, metrics=acc_02)
lr_find(learn)
learn.recorder.plot(suggestion=True)

lr = learn.recorder.min_grad_lr
lr

lr = 0.03311311214825908
learn.fit_one_cycle(5, lr)

learn.unfreeze()
lr_find(learn)
learn.recorder.plot(suggestion=True)

lr2 = learn.recorder.min_grad_lr
lr2

learn.fit_one_cycle(15, slice(lr2, lr/5))

learn.save('stage-01')

interp = ClassificationInterpretation.from_learner(learn)

def show_extremes(learn, k=3, thresh=0.2, show_losses=True):
    preds, y, losses = learn.get_preds(with_loss=True)
    losses = losses.view(preds.shape).sum(dim=1)
    
    if show_losses: sort_idx = np.argsort(losses.numpy())[::-1]
    else: sort_idx = np.argsort(losses.numpy())
        
    imgs = learn.data.valid_ds
    
    fig, ax = plt.subplots(ncols=k, nrows=k, figsize=(10,10))

    for i,axis in zip(sort_idx, ax.flatten()):
        img, actual_label = imgs[i]
        actual_label = ''.join(set(str(actual_label).split(';')))

        pred = preds[i]
        show_image(img, ax=axis)
        pred_label = [c for p,c in zip(pred>=thresh, learn.data.classes) if p]
        loss = losses[i]

        title = f'{"".join(pred_label)} | {str(actual_label)} | {loss.item():.4f}'
        axis.set_title(title)
    fig.suptitle('prediction | actual | loss', fontsize=16)
    plt.show()

show_extremes(learn, show_losses=True)







# Approach 3

from google.colab import drive
drive.mount('/content/drive')

import os
from torch.utils.data import DataLoader,Dataset
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import pandas as pd
from torchvision import models
import torch.nn as nn
from fastai.vision import Path
import torch
from torch.autograd import Variable
from torchsummary import summary

NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
ALL_CHAR_SET = NUMBER + ALPHABET
ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)
MAX_CAPTCHA = 5

def encode(a):
    onehot = [0]*ALL_CHAR_SET_LEN
    idx = ALL_CHAR_SET.index(a)
    onehot[idx] += 1
    return onehot

class Mydataset(Dataset):
    def __init__(self, path, is_train=True, transform=None):
        self.path = path
        if is_train: self.img = os.listdir(self.path)[:1000]
        else: self.img = os.listdir(self.path)[1001:]
        self.transform = transform
        
    def __getitem__(self, idx):
        img_path = self.img[idx]
        img = Image.open(self.path/img_path)
        img = img.convert('L')
        label = Path(self.path/img_path).name[:-4]
        label_oh = []
        for i in label:
            label_oh += encode(i)
        if self.transform is not None:
            img = self.transform(img)
        return img, np.array(label_oh), label
    
    def __len__(self):
        return len(self.img)

transform = transforms.Compose([
    transforms.Resize([224, 224]),
    transforms.ToTensor(),
])

train_ds = Mydataset(Path('/content/drive/My Drive/samples'), transform=transform)
test_ds = Mydataset(Path('/content/drive/My Drive/samples'), False, transform)
train_dl = DataLoader(train_ds, batch_size=100, num_workers=0)
test_dl = DataLoader(test_ds, batch_size=1, num_workers=0)

len(train_ds)

for i in train_ds:
  img,oh,lab=i
  print(lab)
  break

model50 = models.resnet34(pretrained=False)

model50.conv1 = nn.Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3), bias=False)

model50.fc = nn.Linear(in_features=512, out_features=180, bias=True)

model50.cuda();

loss_func = nn.MultiLabelSoftMarginLoss()
optm = torch.optim.Adam(model50.parameters(), lr=0.001)

for epoch in range(110):
    for step, i in enumerate(train_dl):
        img, label_oh, label = i
        img = Variable(img).cuda()
        label_oh = Variable(label_oh.float()).cuda()
        pred = model50(img)
        loss = loss_func(pred, label_oh)
        optm.zero_grad()
        loss.backward()
        optm.step()
        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())

model50.eval();

#y_true = []
#y_pred = []

predict_first_letter =   []
predict_second_letter =  [] 
predict_third_letter =   []
predict_fourth_letter =  []
predict_fifth_letter =   []

Actual_first_letter =   []
Actual_second_letter =  []
Actual_third_letter =   []
Actual_fourth_letter =  []
Actual_fifth_letter =   []

for step, (img, label_oh, label) in enumerate(test_dl):
    img = Variable(img).cuda()
    pred = model50(img)

    c0 = ALL_CHAR_SET[np.argmax(pred.squeeze().cuda().tolist()[0:ALL_CHAR_SET_LEN])]
    c1 = ALL_CHAR_SET[np.argmax(pred.squeeze().cuda().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]
    c2 = ALL_CHAR_SET[np.argmax(pred.squeeze().cuda().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]
    c3 = ALL_CHAR_SET[np.argmax(pred.squeeze().cuda().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]
    c4 = ALL_CHAR_SET[np.argmax(pred.squeeze().cuda().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]
    c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)

    print('label:', label[0], 'pred:', c)

    #y_true.append(label[0])
    #y_pred.append(c)

    predict_first_letter.append (c[0])
    predict_second_letter.append (c[1])
    predict_third_letter.append (c[2])
    predict_fourth_letter.append (c[3])
    predict_fifth_letter.append (c[4])

    Actual_first_letter.append(label[0][0])
    Actual_second_letter.append(label[0][1])
    Actual_third_letter.append(label[0][2])
    Actual_fourth_letter.append(label[0][3])
    Actual_fifth_letter.append(label[0][4])

Total_length = len(Actual_fifth_letter)

correct_first_letter = 0
for i,case in enumerate(Actual_first_letter):
  if case == predict_first_letter[i]:
    correct_first_letter+=1

Accuracy_of_first_letter = (correct_first_letter/Total_length)*100  

correct_second_letter = 0
for i,case in enumerate(Actual_second_letter):
  if case==predict_second_letter[i]:
    correct_second_letter+=1

Accuracy_of_second_letter = (correct_second_letter/Total_length)*100  

correct_third_letter = 0
for i,case in enumerate(Actual_third_letter):
  if case==predict_third_letter[i]:
    correct_third_letter+=1

Accuracy_of_third_letter = (correct_third_letter/Total_length)*100  

correct_fourth_letter = 0
for i,case in enumerate(Actual_fourth_letter):
  if case==predict_fourth_letter[i]:
    correct_fourth_letter+=1

Accuracy_of_fourth_letter = (correct_fourth_letter/Total_length)*100  

correct_fifth_letter = 0
for i,case in enumerate(Actual_fifth_letter):
  if case==predict_fifth_letter[i]:
    correct_fifth_letter+=1

Accuracy_of_fifth_letter = (correct_fifth_letter/Total_length)*100  

print('Accuracy_of_first_letter: ', Accuracy_of_first_letter)
print('Accuracy_of_second_letter: ', Accuracy_of_second_letter)
print('Accuracy_of_third_letter: ', Accuracy_of_third_letter)
print('Accuracy_of_fourth_letter: ', Accuracy_of_fourth_letter)
print('Accuracy_of_fifth_letter: ', Accuracy_of_fifth_letter )





total = len(y_true)
correct = 0
for i, case in enumerate(y_true):
    if case == y_pred[i]:
        correct = correct + 1

#Accuracy = round((correct/total)*100,2)
#print('Accuracy', Accuracy,'%')



